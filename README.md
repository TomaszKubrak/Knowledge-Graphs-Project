
## Ontology Design

Each paper utilizes a custom ontology beyond the combined ontology framework. Below are two ontologies derived from specific research papers, including class structures, properties, and example instances.

---

### ğŸ§  **Ontology: AI Assistance in Noisy Image Classification**
*Based on:* _"An Empirical Investigation of Reliance on AI-Assistance in a Noisy-Image Classification Task"_ by H. Tejeda Lemus et al.  
**Prefix:** `ai`

#### ğŸ“¦ Classes
- `AIModel` â€“ An AI classifier/system assisting humans (subclass of `:ArtificialAgent`)
- `AIOffCondition`, `AIOnCondition` â€“ Conditions indicating AI availability
- `Accuracy`, `AutomationBias`, `OptimalReliance`, `ConfidenceRating` â€“ Subclasses of `PerformanceMetric` representing evaluation aspects
- `ClassifierAboveBaseline`, `ClassifierBelowBaseline`, `ClassifierOnBaseline` â€“ AI performance categories
- `ExperimentalCondition` â€“ Experimental setup descriptor
- `NoisyImageClassificationTask` â€“ A decision-making task under uncertainty (subclass of `:InteractionTask`)
- `Participant` â€“ Human subjects
- `PerformanceMetric` â€“ Evaluation metrics for human/AI performance

#### ğŸ”— Object Properties
- `achievedMetric` â€“ Links `NoisyImageClassificationTask` to a `PerformanceMetric`
- `hasCondition` â€“ Associates a task with `AIOnCondition` or `AIOffCondition`
- `involvesParticipant` â€“ Links task to a `Participant`
- `usesAIModel` â€“ Specifies the `AIModel` used

#### ğŸ”¢ Data Properties
- `hasAccuracyValue` â€“ Numeric accuracy (range: `xsd:decimal`)
- `hasAutomationBiasScore` â€“ Float score for automation bias
- `hasConfidenceValue` â€“ Confidence level (float/decimal)
- `hasOptimalRelianceGap` â€“ Deviation from optimal performance (float)

#### ğŸ‘¤ Named Individuals
- `aiAssistancePaper` â€“ The paper entity
- `classifier above baseline`, `on baseline`, `below baseline` â€“ AI performance examples
- `condition ai off`, `condition ai on` â€“ AI availability states
- `participant 001`, `participant 002` â€“ Annotated human participants
- `task p1 t1`, `task p2 t1` â€“ Instances of `NoisyImageClassificationTask`

![Figure 1 â€“ Ontology from noisy image classification paper](/AIpaper.png)


---

### ğŸ•¶ï¸ **Ontology: Generative VR**
*Based on:* _"Computer, Generate! â€“ Investigating User-Controlled Generation of Immersive Virtual Environments"_ by C. Liebers et al.  
**Prefix:** `gv`

#### ğŸ“¦ Classes
- `AllAtOnceFlow`, `CreationBeforeManipulationFlow`, `StepByStepFlow` â€“ Subclasses of `ControlFlow`, defining generation sequences
- `ColoringStep`, `CreationStep`, `DeletionStep`, `MovementStep`, `ScalingStep` â€“ `GenerationStep` subclasses for each VR action
- `ControlFlow` â€“ Base class for orchestration logic
- `ControllerInput`, `HandInput`, `VoiceInput` â€“ Subclasses of `InteractionModality`
- `EnvironmentGeneration` â€“ Environment generation task (subclass of `:Scenario`)
- `EvaluationMetric`, `SpatialAccuracy`, `TaskCompletionTime`, `UsabilityScore`, `UserExperienceScore` â€“ Evaluation classes
- `GenerationStep` â€“ Steps in the VR object generation process
- `InteractionModality` â€“ Subclass of `:InteractionMethod`
- `Participant` â€“ A `:Human` participant in the VR scenario

#### ğŸ”— Object Properties
- `achievedResult` â€“ Links generation scenario to `EvaluationMetric`
- `employsGenerationStep` â€“ Connects `EnvironmentGeneration` with specific `GenerationStep`s
- `hasControlFlow` â€“ Specifies the `ControlFlow` used
- `hasModality` â€“ Indicates the interaction method
- `involvesParticipant` â€“ Links scenario to participants

#### ğŸ”¢ Data Properties
- `hasRotationError` â€“ Rotational mismatch (`xsd:float`)
- `hasSUSScore` â€“ Usability score (`xsd:float`)
- `hasTimeInSeconds` â€“ Task duration (`xsd:float`)
- `hasTranslationError` â€“ Positional error (`xsd:float`)
- `hasUEQScore` â€“ User experience score (`xsd:float`)

#### ğŸ‘¤ Instances
- `VR GardenStudy` â€“ An `EnvironmentGeneration` instance using multiple generation steps, control flows, and modalities
- `all at once flow`, `creation before manipulation flow`, `step by step flow` â€“ Control flow examples
- `creation step`, `movement step`, `deletion step`, `scaling step`, `coloring step` â€“ Generation steps
- `controller input modality`, `hand input modality`, `voice input modality` â€“ Interaction modalities
- `study participant 001` â€“ A participant object

![Figure 2 â€“ Ontology from VR generation study](gv.png)


